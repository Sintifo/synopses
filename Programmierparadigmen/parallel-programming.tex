
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "propa"
%%% End:

\section{Parallele Programmierung}

\subsection{Motivation}
\begin{itemize}
  \item Moore's law erreicht Grenzen für Anzahl der Schaltkreise / Taktung
  \item Trotzdem Rechenpower für Medizin, Wetter, \ldots
  \item Performance durch mehrere Kerne und Parallelverarbeitung
\end{itemize}
\(\Rightarrow\) Softwareentwickler müssen Parallelverarbeitung beherrschen

\subsection{Parallelism vs. Concurrency}
\textbf{Parallelism}: Mindestens 2 Threads werden gleichzeitig ausgeführt.\\
\textbf{Concurrency}: Mindestens 2 Threads machen Fortschritt.\\
Concurrency ist die Verallgemeinerung von Parallelism.

\subsection{Ansätze}
\textbf{Geteilter Speicher}\\
Jeder Prozess kann jeden Speicher bearbeiten. Auf Mehrkernprozessoren.\\
\textbf{Verteilter Speicher}\\
Prozesse schicken sich gegenseitig Nachrichten. Z.B. in Clustern.

\subsection{Flynn's Taxonomy}
\begin{enumerate}
  \item SISD:\@ Single Instruction x Single Data --- von Neumann
  \item SIMD:\@ Single Instruction x Multiple Data --- Vector Prozessoren
  \item MIMD:\@ Multiple Instruction x Multiple Data --- Mehrkernprozessor
  \item MISD:\@ Multiple Instruction x Single Data --- Pipelines / Redundante Systeme
\end{enumerate}

\subsection{Aufteilung des Problems}
\textbf{Task parallelism}: Aufteilung in verschiedene Funktionen.\\
\textbf{Data prallelism}: Aufteilen der Daten auf verschiedene Prozesse.\\


\subsection{Amdahl's Law}
Berechnung der Beschleunigung \(S(n) = \frac{T(1)}{T(n)} = \frac{\text{Zeit eines Prozessors}}{\text{Zeit von n Prozessoren}}\)\\
Nach Amdahl's Law kann maximal eine Beschleunigung erreicht werden, bei \(p\) Prozent des Programms parallelisierbar von:
\[S(n) = \frac{1}{(1-p) + \frac{p}{n}}\]

\subsection{MPI}
Kommunikation von Prozession durch Nachrichten.
MPI ist ein offenes Interface, welches Wert auf best practices legt.\\
Grundlegend wird SIMD verwendet.\\

\textbf{Communicators}\\
Ist eine Gruppe von Prozessen. Der Standard ist \code{MPI\_COMM\_WORLD}, die Sammlung aller Prozesse.\\
Jeder Prozess ist durch seinen Rang \(R_j\ (0 \leq R_j \leq N) \) eindeutig identifiziert. Wird durch \code{MPI\_Comm\_rank} erhalten.
\code{MPI\_Comm\_size} gibt die Anzahl aller Prozesse zurück.
\begin{lstlisting}
int size, my_rank;
int MPI_Comm_size(MPI_COMM_WORLD, &size);
int MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);
\end{lstlisting}

\textbf{Kommunikation}\\
Baut auf send und receive Operationen auf. Diese sind für Kommunikation zwischen einzelnen Prozessen.
Für Kommunikation mit allen anderen spezifiziert MPI Broadcast Operationen.
\begin{lstlisting}
int MPI_Send(void* buffer, int count, MPI_Datatype datatype, int dest,
             int tag, MPI_Comm comm)
int MPI_Recv(void* buffer, int count, MPI_Datatype datatype, int source,
             int tag, MPI_Comm comm, MPI_Stats* status)
\end{lstlisting}

\textbf{Synchronization}\\
Barriere blockt alle Prozesse bis alle am selben Punkt sind.
\begin{lstlisting}
int MPI_Barrier(MPI_COMM_WORLD);
\end{lstlisting}

\textbf{Temporal Sorting}\\
Nachrichten sind non-overtaking. Also erste Nachricht eines Senders kommt auch als erstes an. Setzt vorraus, das auch ein
Empfänger dafür verfügbar ist.\\

\textbf{Kommunikationsmodi}\\
Sending:
\begin{itemize}
  \item Synchronous
  \item Buffered
  \item Ready
  \item Standard
  \end{itemize}
  
\textbf{Blocking Send}
\begin{lstlisting}
  MPI_Send
  MPI_Bsend
  MPI_Ssend
  MPI_Rsend
\end{lstlisting}

\textbf{Non-blocking Send}
\begin{lstlisting}
  int MPI_Isend(void* buf, int count MPI_Datatype type, int dest, int tag, 
                MPI_Comm comm, MPI_Request* request)
  int MPI_Irecv(void* buf, int count, MPI_Datatype type, int src, int tag, 
                MPI_Comm comm, MPI_Request* request)
  int MPI_Test(MPI_Request* r, int* flag, MPI_Status* s)
  int MPI_Wait(MPI_Request* r, MPI_Status* s)
\end{lstlisting}

\textbf{Data Distribution}\\
Kann durch Broadcast erreicht werden. Root versendet Daten an alle.
\begin{itemize}
  \item Broadcast
  \item Scatter
  \item Gather
  \item Allgather = Gather + Broadcast
  \item Alltoall
  \item Multi-Broadcast = Gather + Broadcast
\end{itemize}
Vektorvarianten sind mit angehängtem v verfügbar\\

\textbf{Reduce}\\
Verschiedene Reduce Varianten, wenden Gather an und berechnen aus Werten einen Wert durch Funktion.
Verschiedene Varianten verfügbar:
\begin{itemize}
  \item Reduce
  \item Allreduce
  \item Reduce-scatter
  \item Scan
\end{itemize}


\textbf{MapReduce}\\
Programmiermodell von Google entwickelt.
Besteht aus 3 Schritten: Map, Shuffle und Reduce.


\subsection{Java Parallel}
Grundlagen sollten aus SWTI bekannt sein. Demnach werden hier nur die erweiterten Konzepte vorgestellt.\\

\textbf{Atomic Types}\\
Typen in Java welche Thread-safe verwendet können, da sie sich selbst synchronisieren.
Befinden sich in \code{java.util.concurrent.atomic}\\
Durch \code{volatile} lässt sich auch die Synchronisierung von anderen Typen erzwingen.\\

\textbf{Locks}\\
Java stellt das \code{ReentrantLock} und \code{ReentrantReadWriteLock} zur Verfügung. Diese können fair oder unfair sein.
Außerdem stellt Java auch Counting Semaphores und Barriers bereit.\\

\textbf{Executor}\\
Eine Executor abstrahiert von der Erstellung eines Threads. Dabei ist Executor ein Interface, welches Dienst Threads zu erstellen
oder vorhandene Threads wieder zu verwenden.\\

\textbf{ExecutorService}\\
Ein Subinterface von Executor welches einfaches Erstellen von Threadpools ermöglicht.\\

\textbf{Callable}\\
Interface welches es ermöglicht Ergebnisse von Threads zurück zu geben.
Definiert die Methode \code{public String call()}\\

\textbf{Futures}\\
Vergleichbar mit Promises in JavaScript ermöglichen Futures den Zukünftigen Rückgabewert zur Verfügung zu stellen.
Die \code{get}-Methode blockt, bis der Thread abgeschlossen ist.\\

\textbf{Fork-Join}\\
Effektiv für divide-and-conquer Algorithmen. Erstelle ForkJoinTask und führe Ihn mit ForkJoinPool aus.\\

\textbf{Thread-Safe Classes}\\
BlockingQuee inklusive einiger Implementierungen.\\

\textbf{Streams}\\
Jede Collection kann durch \code{collection.stream()} als Stream verwendet werden.
Dabei können häufige Operationen wie filter, map, reduce und andere verwendet werden.
Diese werden vergleichbar mit Haskell Lazy ausgewertet.
Streams existieren auch als Int/Double/...-Stream. Diese erhält man durch mapToInt/Double/...
Nur auf Zahlenstreams existieren Operationen wie average.

\subsection{Actor Model}
Konzeptuelles Model für paralleles Rechnen. Basiert auf Aktoren und Nachrichten.\\
Aktoren können nur auf Ihren eigenen Zustand und eigenen Speicher zugreifen. Kommunikation mit anderen Aktoren geschieht
durch Austausch von Nachrichten. \\
Ein Aktor kann entweder durch die Umgebung erstellt werden (Root Aktor),
oder durch einen anderen Aktor. In diesem Fall wird der andere Aktor sein Supervisor und delegiert Arbeit an Ihn und
kann ihn im Zweifel eines Crashes neustarten.\\
Das Modell ermöglicht gute Skalierbarkeit, da es egal ist auf welcher Instanz andere Aktoren laufen.\\
\textbf{Implementierungen}
\begin{itemize}
  \item Erlang
  \item Akka (Java/Scala)
  \item Akka.NET
\end{itemize}
\textbf{Akka Java}\\
Kreiren eines Aktors \code{extends AbstractActor} und implementiere \code{Receive createReceive();}\\
Dabei hilft \code{receiveBuilder()} und \code{match(Class<P> type, UnitApply<P> apply)}
Alternativ noch \code{match} und \code{matchAny}.\\
Aktoren werden durch Props erstellt. \code{Props Props.create(Class<?> actorType, Object... parameters)}.
Und durch die ActorRefFactory instanziiert \code{ActorRef actorOf(Props props)}.\\
Nachrichten werden mit \code{void tell(Object message, ActorRef sender)} und \code{Future<?> Patterns.ask(ActorRef target, Object msg, Timeout timeout)}
versandt.\\
Stoppen von Akoren erfolgt durch \code{void stop(ActorRef actorToStop)} oder \code{PoisonPill.getInstance} und senden dieser.